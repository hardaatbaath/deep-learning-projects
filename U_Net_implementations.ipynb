{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.nn.functional import relu"
      ],
      "metadata": {
        "id": "V6JHseX91iRn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "lDEZfIccz6Sl"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "\n",
        "  def __init__(self, n_class):\n",
        "    super().__init__()\n",
        "\n",
        "    # Encoder\n",
        "    # -------\n",
        "    # input: 572x572x3\n",
        "    self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1) # output: 570x570x64\n",
        "    self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1) # output: 568x568x64\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 284x284x64\n",
        "\n",
        "    # input: 284x284x64\n",
        "    self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 282x282x128\n",
        "    self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 280x280x128\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n",
        "\n",
        "    # input: 140x140x128\n",
        "    self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 138x138x256\n",
        "    self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 136x136x256\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n",
        "\n",
        "    # input: 68x68x256\n",
        "    self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 66x66x512\n",
        "    self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 64x64x512\n",
        "    self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n",
        "\n",
        "    # input: 32x32x512\n",
        "    self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) # output: 30x30x1024\n",
        "    self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1) # output: 28x28x1024\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "    self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
        "    self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "    self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "    self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "    self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "    self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "    self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "\n",
        "    self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "    self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "    self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "    # Output layer\n",
        "    self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Encoder\n",
        "    xe11 = relu(self.e11(x))\n",
        "    xe12 = relu(self.e12(xe11))\n",
        "    xp1 = self.pool1(xe12)\n",
        "\n",
        "    xe21 = relu(self.e21(xp1))\n",
        "    xe22 = relu(self.e22(xe21))\n",
        "    xp2 = self.pool2(xe22)\n",
        "\n",
        "    xe31 = relu(self.e31(xp2))\n",
        "    xe32 = relu(self.e32(xe31))\n",
        "    xp3 = self.pool3(xe32)\n",
        "\n",
        "    xe41 = relu(self.e41(xp3))\n",
        "    xe42 = relu(self.e42(xe41))\n",
        "    xp4 = self.pool4(xe42)\n",
        "\n",
        "    xe51 = relu(self.e51(xp4))\n",
        "    xe52 = relu(self.e52(xe51))\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    xu1 = self.upconv1(xe52)\n",
        "    xu11 = torch.cat([xu1, xe42], dim=1)\n",
        "    xd11 = relu(self.d11(xu11))\n",
        "    xd12 = relu(self.d12(xd11))\n",
        "\n",
        "    xu2 = self.upconv2(xd12)\n",
        "    xu22 = torch.cat([xu2, xe32], dim=1)\n",
        "    xd21 = relu(self.d21(xu22))\n",
        "    xd22 = relu(self.d22(xd21))\n",
        "\n",
        "    xu3 = self.upconv3(xd22)\n",
        "    xu33 = torch.cat([xu3, xe22], dim=1)\n",
        "    xd31 = relu(self.d31(xu33))\n",
        "    xd32 = relu(self.d32(xd31))\n",
        "\n",
        "    xu4 = self.upconv4(xd32)\n",
        "    xu44 = torch.cat([xu4, xe12], dim=1)\n",
        "    xd41 = relu(self.d41(xu44))\n",
        "    xd42 = relu(self.d42(xd41))\n",
        "\n",
        "    # Output layer\n",
        "    out = self.outconv(xd42)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Block"
      ],
      "metadata": {
        "id": "Hu7m4JZ73YyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from functools import reduce\n",
        "import itertools\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from collections import defaultdict\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "vl69cQbM0_Jc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_data(height, width, count):\n",
        "    x, y = zip(*[generate_img_and_mask(height, width) for i in range(0, count)])\n",
        "\n",
        "    X = np.asarray(x) * 255\n",
        "    X = X.repeat(3, axis=1).transpose([0, 2, 3, 1]).astype(np.uint8)\n",
        "    Y = np.asarray(y)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "uzVhrzvH1QVW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_img_and_mask(height, width):\n",
        "    shape = (height, width)\n",
        "\n",
        "    triangle_location = get_random_location(*shape)\n",
        "    circle_location1 = get_random_location(*shape, zoom=0.7)\n",
        "    circle_location2 = get_random_location(*shape, zoom=0.5)\n",
        "    mesh_location = get_random_location(*shape)\n",
        "    square_location = get_random_location(*shape, zoom=0.8)\n",
        "    plus_location = get_random_location(*shape, zoom=1.2)\n",
        "\n",
        "    # Create input image\n",
        "    arr = np.zeros(shape, dtype=bool)\n",
        "    arr = add_triangle(arr, *triangle_location)\n",
        "    arr = add_circle(arr, *circle_location1)\n",
        "    arr = add_circle(arr, *circle_location2, fill=True)\n",
        "    arr = add_mesh_square(arr, *mesh_location)\n",
        "    arr = add_filled_square(arr, *square_location)\n",
        "    arr = add_plus(arr, *plus_location)\n",
        "    arr = np.reshape(arr, (1, height, width)).astype(np.float32)\n",
        "\n",
        "    # Create target masks\n",
        "    masks = np.asarray([\n",
        "        add_filled_square(np.zeros(shape, dtype=bool), *square_location),\n",
        "        add_circle(np.zeros(shape, dtype=bool), *circle_location2, fill=True),\n",
        "        add_triangle(np.zeros(shape, dtype=bool), *triangle_location),\n",
        "        add_circle(np.zeros(shape, dtype=bool), *circle_location1),\n",
        "         add_filled_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
        "        # add_mesh_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
        "        add_plus(np.zeros(shape, dtype=bool), *plus_location)\n",
        "    ]).astype(np.float32)\n",
        "\n",
        "    return arr, masks"
      ],
      "metadata": {
        "id": "QQ7IKsf23eHH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_square(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "    arr[x-s,y-s:y+s] = True\n",
        "    arr[x+s,y-s:y+s] = True\n",
        "    arr[x-s:x+s,y-s] = True\n",
        "    arr[x-s:x+s,y+s] = True\n",
        "\n",
        "    return arr"
      ],
      "metadata": {
        "id": "kIKLipS33gzB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_filled_square(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "\n",
        "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
        "\n",
        "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, yy > y - s, yy < y + s]))"
      ],
      "metadata": {
        "id": "7t6glI7V3kgy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logical_and(arrays):\n",
        "    new_array = np.ones(arrays[0].shape, dtype=bool)\n",
        "    for a in arrays:\n",
        "        new_array = np.logical_and(new_array, a)\n",
        "\n",
        "    return new_array"
      ],
      "metadata": {
        "id": "V58woYE_3nZ7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_mesh_square(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "\n",
        "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
        "\n",
        "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, xx % 2 == 1, yy > y - s, yy < y + s, yy % 2 == 1]))"
      ],
      "metadata": {
        "id": "ih6abPFx3rfp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_triangle(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "\n",
        "    triangle = np.tril(np.ones((size, size), dtype=bool))\n",
        "\n",
        "    arr[x-s:x-s+triangle.shape[0],y-s:y-s+triangle.shape[1]] = triangle\n",
        "\n",
        "    return arr"
      ],
      "metadata": {
        "id": "rQK5GPN_3sZK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_circle(arr, x, y, size, fill=False):\n",
        "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
        "    circle = np.sqrt((xx - x) ** 2 + (yy - y) ** 2)\n",
        "    new_arr = np.logical_or(arr, np.logical_and(circle < size, circle >= size * 0.7 if not fill else True))\n",
        "\n",
        "    return new_arr"
      ],
      "metadata": {
        "id": "5aQBwoNi3vyJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_plus(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "    arr[x-1:x+1,y-s:y+s] = True\n",
        "    arr[x-s:x+s,y-1:y+1] = True\n",
        "\n",
        "    return arr"
      ],
      "metadata": {
        "id": "FtdYqxjm3wVB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_location(width, height, zoom=1.0):\n",
        "    x = int(width * random.uniform(0.1, 0.9))\n",
        "    y = int(height * random.uniform(0.1, 0.9))\n",
        "\n",
        "    size = int(min(width, height) * random.uniform(0.06, 0.12) * zoom)\n",
        "\n",
        "    return (x, y, size)"
      ],
      "metadata": {
        "id": "HWCM_Z973yUp"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_img_array(img_array, ncol=3):\n",
        "    nrow = len(img_array) // ncol\n",
        "\n",
        "    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4))\n",
        "\n",
        "    for i in range(len(img_array)):\n",
        "        plots[i // ncol, i % ncol]\n",
        "        plots[i // ncol, i % ncol].imshow(img_array[i])"
      ],
      "metadata": {
        "id": "O9KubC0x30YJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_side_by_side(img_arrays):\n",
        "    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n",
        "\n",
        "    plot_img_array(np.array(flatten_list), ncol=len(img_arrays))"
      ],
      "metadata": {
        "id": "LjKu9Cix34Ct"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_errors(results_dict, title):\n",
        "    markers = itertools.cycle(('+', 'x', 'o'))\n",
        "\n",
        "    plt.title('{}'.format(title))\n",
        "\n",
        "    for label, result in sorted(results_dict.items()):\n",
        "        plt.plot(result, marker=next(markers), label=label)\n",
        "        plt.ylabel('dice_coef')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(loc=3, bbox_to_anchor=(1, 0))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wDSK9YVU36aV"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masks_to_colorimg(masks):\n",
        "    colors = np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n",
        "\n",
        "    colorimg = np.ones((masks.shape[1], masks.shape[2], 3), dtype=np.float32) * 255\n",
        "    channels, height, width = masks.shape\n",
        "\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            selected_colors = colors[masks[:,y,x] > 0.5]\n",
        "\n",
        "            if len(selected_colors) > 0:\n",
        "                colorimg[y,x,:] = np.mean(selected_colors, axis=0)\n",
        "\n",
        "    return colorimg.astype(np.uint8)"
      ],
      "metadata": {
        "id": "EzoIJ5z538en"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images_and_masks_then_plot():\n",
        "    # Generate some random images\n",
        "    input_images, target_masks = generate_random_data(192, 192, count=3)\n",
        "\n",
        "    for x in [input_images, target_masks]:\n",
        "        print(x.shape)\n",
        "        print(x.min(), x.max())\n",
        "\n",
        "    # Change channel-order and make 3 channels for matplot\n",
        "    input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
        "\n",
        "    # Map each channel (i.e. class) to each color\n",
        "    target_masks_rgb = [masks_to_colorimg(x) for x in target_masks]\n",
        "\n",
        "    # Left: Input image (black and white), Right: Target mask (6ch)\n",
        "    plot_side_by_side([input_images_rgb, target_masks_rgb])"
      ],
      "metadata": {
        "id": "G8_k0B3i3-wd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_transform(inp):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    inp = (inp * 255).astype(np.uint8)\n",
        "\n",
        "    return inp"
      ],
      "metadata": {
        "id": "EsT4NAcw4BLH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimDataset(Dataset):\n",
        "    def __init__(self, count, transform=None):\n",
        "        self.input_images, self.target_masks = generate_random_data(192, 192, count=count)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.input_images[idx]\n",
        "        mask = self.target_masks[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return [image, mask]"
      ],
      "metadata": {
        "id": "p0MHwNBU4Dpb"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loaders():\n",
        "    # use the same transformations for train/val in this example\n",
        "    trans = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
        "    ])\n",
        "\n",
        "    train_set = SimDataset(100, transform = trans)\n",
        "    val_set = SimDataset(20, transform = trans)\n",
        "\n",
        "    image_datasets = {\n",
        "        'train': train_set, 'val': val_set\n",
        "    }\n",
        "\n",
        "    batch_size = 25\n",
        "\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "        'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    }\n",
        "\n",
        "    return dataloaders"
      ],
      "metadata": {
        "id": "numlQIiO4GNy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(pred, target, smooth=1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "\n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "40IQaNV94IPw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    pred = F.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "\n",
        "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "3KVaqrVX4I3U"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))"
      ],
      "metadata": {
        "id": "OgwF41vU4Nvl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    dataloaders = get_data_loaders()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    print(\"LR\", param_group['lr'])\n",
        "\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = calc_loss(outputs, labels, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(\"saving best model\")\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "AGwzK1qC4Qv_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(UNet):\n",
        "    num_class = 6\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = UNet(num_class).to(device)\n",
        "\n",
        "    optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
        "\n",
        "    model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)\n",
        "\n",
        "    model.eval()  # Set model to the evaluation mode\n",
        "\n",
        "    trans = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # imagenet\n",
        "    ])\n",
        "    # # Create another simulation dataset for test\n",
        "    test_dataset = SimDataset(3, transform = trans)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
        "\n",
        "    # Get the first batch\n",
        "    inputs, labels = next(iter(test_loader))\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Predict\n",
        "    pred = model(inputs)\n",
        "    # The loss functions include the sigmoid function.\n",
        "    pred = F.sigmoid(pred)\n",
        "    pred = pred.data.cpu().numpy()\n",
        "    print(pred.shape)\n",
        "\n",
        "    # Change channel-order and make 3 channels for matplot\n",
        "    input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
        "\n",
        "    # Map each channel (i.e. class) to each color\n",
        "    target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
        "    pred_rgb = [masks_to_colorimg(x) for x in pred]\n",
        "\n",
        "    plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
      ],
      "metadata": {
        "id": "_bmSBypo4U1P"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(UNet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "IAgJl3DI4cZ4",
        "outputId": "e09437af-7b9d-4440-93b6-6657d3d30e0e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/59\n",
            "----------\n",
            "LR 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-ac056cbb25bf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-ebac36316157>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(UNet)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to the evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-438c704a75a6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-67ea02740e2c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mxp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mxe41\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me41\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mxe42\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me42\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mxp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwQ8TY814fAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}